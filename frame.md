# 스팸 SNS 메시지 알리미 프로젝트 - 프레임워크 제안

---

## 1. 프로젝트 개요

* **프로젝트명**: 스팸 SNS 메시지 알리미
* **목표**: DM, 페이스북 메시지 등 SNS 서비스에 도입하여 스팸, 광고 성격의 메시지 수신 시 경고 및 차단 기능을 제공합니다.
* **핵심 기능**: 실시간 감시 및 차단/경고, 자연어 처리(NLP) 기반 스팸 분류, 메시지 데이터 수집.
* **개발 기간**: 3주
* **팀 구성**: 2명
* **작업 환경**: 데스크톱 2대 (로컬 환경)

---

## 2. 프레임워크 핵심 구성 요소

이 프로젝트는 **메시지 감시 및 수집 → NLP 기반 스팸 분류 → 알림/차단**의 흐름을 가집니다. 이를 효과적으로 지원하기 위한 핵심 구성 요소는 다음과 같습니다.

* **메시지 수집 및 전처리 모듈**: SNS 서비스로부터 메시지를 가져와 NLP 모델이 처리하기 좋은 형태로 정제합니다. 초기에는 로컬 데스크톱에서 직접 메시지 스트림을 받거나 파일에서 읽는 방식이 될 것입니다.
* **NLP 모델 추론(Inference) 모듈**: 수집된 메시지를 분석하여 스팸 여부를 판단합니다. '가벼운 모델' 요구사항에 맞춰 최적화된 모델을 사용해야 합니다.
* **규칙 기반/추가 필터링 모듈**: NLP 모델의 오탐을 줄이거나, 특정 키워드/패턴에 대한 즉각적인 대응을 위해 사용합니다.
* **알림 및 차단 액션 모듈**: 스팸으로 분류된 메시지에 대해 사용자에게 경고를 보내거나, 필요시 메시지를 차단하는 기능을 수행합니다.
* **데이터 관리 모듈**: 수집된 메시지, 스팸 분류 결과, 사용자 피드백 등을 MySQL 데이터베이스에 저장하고 관리합니다.
* **UI/대시보드 모듈**: Node.js(UI)를 사용하여 사용자가 스팸 현황을 확인하고, 설정(예: 차단 키워드 추가, 알림 설정)을 할 수 있는 인터페이스를 제공합니다.

---

## 3. 추천 기술 스택 및 라이브러리

주어진 제약 조건과 목표를 달성하기 위한 구체적인 기술 스택 및 라이브러리 조합입니다.

* **백엔드/코어 로직 (Python)**:
    * **웹 프레임워크**: **FastAPI** (또는 Flask). 가볍고 빠르며, RESTful API 구축에 적합합니다. 비동기 처리와 자동 문서화(Swagger UI) 기능을 제공하여 협업에 용이합니다.
    * **NLP 라이브러리**:
        * **Hugging Face `transformers`**: 사전 학습된 경량 언어 모델(예: DistilBERT, KoBERT)을 활용하여 스팸 분류 모델을 구축하거나 파인튜닝합니다.
        * **`scikit-learn`**: 기본적인 텍스트 분류(TF-IDF + Naive Bayes/SVM) 또는 규칙 기반 필터링에 활용될 수 있습니다.
        * **`konlpy` (한국어 NLP)**: 한국어 메시지 처리를 위한 형태소 분석 등 전처리 과정에 필수적입니다.
    * **데이터베이스 연동**: **SQLAlchemy** (Python ORM)를 사용하여 MySQL과의 연동을 추상화하고 코드 가독성을 높입니다.
    * **데이터 처리**: `pandas` (데이터 수집 및 전처리 과정에서 유용).
* **프론트엔드 (Node.js/UI)**:
    * **웹 프레임워크**: **Express.js**. Node.js 기반의 경량 웹 프레임워크로, 백엔드 Python API와 통신하며 사용자 인터페이스를 제공하는 데 적합합니다.
    * **데이터 시각화**: Chart.js, D3.js (스팸 통계 등을 대시보드에 표시할 때 고려).
* **데이터베이스**:
    * **MySQL**: 메시지 원본, 분류 결과, 사용자 설정, 학습 데이터 등을 저장합니다.

---

## 4. 아키텍처 (모놀리식)

**스팸 SNS 메시지 알리미 - 모놀리식 아키텍처 다이어그램**

+------------------------------------+
|          사용자 인터페이스          |
|        (Node.js / Express.js)      |
|    - 대시보드, 설정 관리           |
|    - Python 백엔드 API 호출        |
+------------------------------------+
|
| HTTP / REST API
V
+------------------------------------+
|          AI 백엔드 서비스          |
|             (Python)               |
| +--------------------------------+ |
| | 메시지 수집 & 전처리 모듈      | | <-- (데스크톱 로컬 메시지 스트림/파일 입력)
| | (SNS 연동, JSON 파싱, 정제)    | |
| +--------------------------------+ |
| | NLP 모델 추론 모듈             | |
| | (Hugging Face Transformers,   | |
| |  scikit-learn, konlpy)         | |
| +--------------------------------+ |
| | 규칙 기반/추가 필터링 모듈       | |
| +--------------------------------+ |
| | 알림 및 차단 액션 모듈         | |
| +--------------------------------+ |
| | 데이터 관리 모듈 (SQLAlchemy)  | |
| +--------------------------------+ |
+------------------------------------+
|
| SQL (TCP/IP)
V
+------------------------------------+
|            MySQL 데이터베이스      |
|   - 원본 메시지, 분류 결과,      |
|   - 사용자 설정, 학습 데이터     |
+------------------------------------+

**아키텍처 설명:**

1.  **사용자 인터페이스 (Node.js/Express.js)**: 웹 기반 대시보드를 제공하여 스팸 메시지 현황 모니터링 및 설정 변경(차단 규칙 추가, 알림 설정)을 가능하게 합니다. Python 백엔드와 **RESTful API**를 통해 통신합니다.
2.  **AI 백엔드 서비스 (Python)**: 단일 Python 애플리케이션으로 모든 핵심 로직을 포함합니다.
    * **메시지 수집**: 초기에는 **특정 형식의 파일 입력(JSON 등)**을 통해 메시지를 모의 수신하는 방안이 현실적입니다.
    * **전처리**: 수집된 메시지를 NLP 모델이 처리하기 적합한 형태로 정제합니다.
    * **NLP 모델 추론**: 경량 NLP 모델(예: DistilBERT, KoBERT 기반)로 스팸 여부를 판단합니다.
    * **필터링**: NLP 모델의 결과를 보완하거나 특정 키워드/패턴에 우선적으로 반응하는 **규칙 기반 필터링**을 추가합니다.
    * **액션**: 스팸으로 판단된 메시지에 대해 UI를 통해 경고를 띄우거나 차단 로직을 수행합니다.
    * **데이터 관리**: 모든 스팸 분류 이력, 사용자 설정, 메시지 원본 등을 MySQL에 저장합니다.
3.  **MySQL 데이터베이스**: 모든 영속적인 데이터를 저장합니다.

---

## 5. 개발 및 협업 전략 (3주, 2인 팀)

* **역할 분담**:
    * **개발자 1 (Python 백엔드 & NLP)**: 메시지 수집/전처리, NLP 모델 연동, 스팸 분류 로직, 데이터베이스 연동 및 API 구현.
    * **개발자 2 (Node.js UI & 알림/차단 로직)**: 사용자 인터페이스 개발, Python 백엔드 API 연동, 알림/차단 액션 구현.
    * 두 개발자 모두 MySQL 스키마 설계 및 관리에 함께 참여합니다.
* **초기 단계 목표 설정**:
    * **1주차**: 환경 설정 (Python, Node.js, MySQL), Flask/FastAPI 및 Express.js 기본 서버 구축, MySQL 연동 확인, NLP 모델 로드 및 간단한 예제 실행.
    * **2주차**: 백엔드 메시지 수집(파일 입력) 및 NLP 추론 API 연동, UI에서 스팸 분류 결과 표시 및 설정 저장/불러오기 기능 구현.
    * **3주차**: 백엔드-UI 통합 및 안정화, 알림/차단 액션, 규칙 기반 필터링 추가, 성능 최적화 및 기본적인 오류 처리/로깅.
* **버전 관리**: **Git**을 사용하여 코드 변경 이력을 관리하고, GitHub/GitLab/Bitbucket 등 온라인 저장소를 활용하여 협업합니다.
* **작업 환경**: 데스크톱 두 대에서 각자 개발 후 Git을 통해 코드를 합칩니다. 개발 서버는 각자 로컬에서 실행하고, 필요시 IP 주소를 통해 서로의 API를 호출하도록 설정합니다.

---

## 6. 고려사항 및 제언

* **SNS 서비스 연동의 현실적 제약**: 3주 기간 내에 실제 SNS 서비스(DM, 페이스북 메시지 등)와 직접 연동하는 것은 매우 어렵습니다. 초기에는 **특정 형식의 더미 메시지 데이터(JSON 파일)**를 사용하여 개발을 진행하고, 실제 SNS 연동은 향후 과제로 남겨두는 것이 현실적입니다. 메시지 수집 모듈은 원본을 가져오는 부분을 나중에 확장성을 고려하여 분리하여 설계합니다.
* **AI 모델 학습 데이터**: 스팸 분류 모델을 학습시키려면 스팸 메시지와 정상 메시지 데이터셋이 필요합니다. 3주 내 직접 구축은 어려우므로, **공개된 스팸/정상 메시지 데이터셋을 활용하거나 사전 학습된 모델을 활용하는 데 집중**해야 합니다.
* **보안**: 데스크톱 로컬 환경이지만, 향후 확장을 고려하여 기본적인 보안 원칙(DB 접근 권한, API 키 관리 등)을 염두에 두는 것이 좋습니다.
* **지속적인 피드백**: 짧은 개발 기간이므로, 두 팀원 간 긴밀하게 소통하며 주간 목표를 설정하고 달성 여부를 공유하는 것이 중요합니다.

---
